"use strict";(globalThis.webpackChunkphysical_ai_humanoid_robotics_book=globalThis.webpackChunkphysical_ai_humanoid_robotics_book||[]).push([[116],{8453(n,e,i){i.d(e,{R:()=>o,x:()=>s});var t=i(6540);const a={},r=t.createContext(a);function o(n){const e=t.useContext(r);return t.useMemo(function(){return"function"==typeof n?n(e):{...e,...n}},[e,n])}function s(n){let e;return e=n.disableParentContext?"function"==typeof n.components?n.components(a):n.components||a:o(n.components),t.createElement(r.Provider,{value:e},n.children)}},8964(n,e,i){i.r(e),i.d(e,{assets:()=>l,contentTitle:()=>o,default:()=>m,frontMatter:()=>r,metadata:()=>s,toc:()=>c});var t=i(4848),a=i(8453);const r={sidebar_position:8,title:"Chapter 8: Unity Visualization and Sensor Simulation"},o="Chapter 8: Unity Visualization and Sensor Simulation",s={id:"part3/chapter8",title:"Chapter 8: Unity Visualization and Sensor Simulation",description:"Learning Objectives",source:"@site/docs/part3/chapter8.md",sourceDirName:"part3",slug:"/part3/chapter8",permalink:"/Physical-AI-Humanoid-Robotics/docs/part3/chapter8",draft:!1,unlisted:!1,editUrl:"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/part3/chapter8.md",tags:[],version:"current",sidebarPosition:8,frontMatter:{sidebar_position:8,title:"Chapter 8: Unity Visualization and Sensor Simulation"},sidebar:"tutorialSidebar",previous:{title:"Chapter 7: URDF and SDF Robot Description Formats",permalink:"/Physical-AI-Humanoid-Robotics/docs/part3/chapter7"},next:{title:"Chapter 9: NVIDIA Isaac SDK and Isaac Sim",permalink:"/Physical-AI-Humanoid-Robotics/docs/part4/chapter9"}},l={},c=[{value:"Learning Objectives",id:"learning-objectives",level:2},{value:"Introduction to Unity for Robotics",id:"introduction-to-unity-for-robotics",level:2},{value:"Unity vs Gazebo for Robotics",id:"unity-vs-gazebo-for-robotics",level:3},{value:"Unity Robotics Package",id:"unity-robotics-package",level:3},{value:"Setting Up Unity for Robotics",id:"setting-up-unity-for-robotics",level:2},{value:"Installation Requirements",id:"installation-requirements",level:3},{value:"Creating a Robotics Project",id:"creating-a-robotics-project",level:3},{value:"Basic Unity Robotics Scene Setup",id:"basic-unity-robotics-scene-setup",level:3},{value:"Physics Simulation in Unity",id:"physics-simulation-in-unity",level:2},{value:"Unity Physics vs Traditional Robotics Physics",id:"unity-physics-vs-traditional-robotics-physics",level:3},{value:"Setting Up Physics for Humanoid Robots",id:"setting-up-physics-for-humanoid-robots",level:3},{value:"Collision Detection and Response",id:"collision-detection-and-response",level:3},{value:"Sensor Simulation in Unity",id:"sensor-simulation-in-unity",level:2},{value:"Camera Simulation",id:"camera-simulation",level:3},{value:"LIDAR Simulation",id:"lidar-simulation",level:3},{value:"IMU Simulation",id:"imu-simulation",level:3},{value:"Advanced Visualization Techniques",id:"advanced-visualization-techniques",level:2},{value:"High-Fidelity Rendering",id:"high-fidelity-rendering",level:3},{value:"Environment Creation",id:"environment-creation",level:3},{value:"Integration with ROS 2",id:"integration-with-ros-2",level:2},{value:"ROS# Bridge Setup",id:"ros-bridge-setup",level:3},{value:"TF (Transform) Broadcasting",id:"tf-transform-broadcasting",level:3},{value:"Performance Optimization",id:"performance-optimization",level:2},{value:"Unity Performance Considerations",id:"unity-performance-considerations",level:3},{value:"Best Practices for Unity Robotics",id:"best-practices-for-unity-robotics",level:2},{value:"Architecture Best Practices",id:"architecture-best-practices",level:3},{value:"Visualization Best Practices",id:"visualization-best-practices",level:3},{value:"Troubleshooting Common Issues",id:"troubleshooting-common-issues",level:2},{value:"Performance Issues",id:"performance-issues",level:3},{value:"Sensor Synchronization",id:"sensor-synchronization",level:3},{value:"Knowledge Check",id:"knowledge-check",level:2},{value:"Summary",id:"summary",level:2},{value:"Next Steps",id:"next-steps",level:2}];function d(n){const e={code:"code",h1:"h1",h2:"h2",h3:"h3",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,a.R)(),...n.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(e.h1,{id:"chapter-8-unity-visualization-and-sensor-simulation",children:"Chapter 8: Unity Visualization and Sensor Simulation"}),"\n",(0,t.jsx)(e.h2,{id:"learning-objectives",children:"Learning Objectives"}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsx)(e.li,{children:"Understand Unity's role in robotics visualization"}),"\n",(0,t.jsx)(e.li,{children:"Set up Unity for robot visualization and simulation"}),"\n",(0,t.jsx)(e.li,{children:"Implement physics simulation and sensor simulation in Unity"}),"\n",(0,t.jsx)(e.li,{children:"Create high-fidelity visualizations for humanoid robots"}),"\n"]}),"\n",(0,t.jsx)(e.h2,{id:"introduction-to-unity-for-robotics",children:"Introduction to Unity for Robotics"}),"\n",(0,t.jsx)(e.p,{children:"Unity is a powerful 3D development platform that has gained significant traction in robotics for creating high-fidelity visualizations, photorealistic simulations, and immersive environments. Unlike Gazebo, which is primarily physics-focused, Unity excels in visual quality and can be integrated with robotics frameworks for advanced visualization and simulation capabilities."}),"\n",(0,t.jsx)(e.h3,{id:"unity-vs-gazebo-for-robotics",children:"Unity vs Gazebo for Robotics"}),"\n",(0,t.jsxs)(e.table,{children:[(0,t.jsx)(e.thead,{children:(0,t.jsxs)(e.tr,{children:[(0,t.jsx)(e.th,{children:"Aspect"}),(0,t.jsx)(e.th,{children:"Unity"}),(0,t.jsx)(e.th,{children:"Gazebo"})]})}),(0,t.jsxs)(e.tbody,{children:[(0,t.jsxs)(e.tr,{children:[(0,t.jsx)(e.td,{children:(0,t.jsx)(e.strong,{children:"Visual Quality"})}),(0,t.jsx)(e.td,{children:"Photorealistic graphics"}),(0,t.jsx)(e.td,{children:"Good but not photorealistic"})]}),(0,t.jsxs)(e.tr,{children:[(0,t.jsx)(e.td,{children:(0,t.jsx)(e.strong,{children:"Physics Simulation"})}),(0,t.jsx)(e.td,{children:"Good (Unity Physics)"}),(0,t.jsx)(e.td,{children:"Excellent (ODE, Bullet, DART)"})]}),(0,t.jsxs)(e.tr,{children:[(0,t.jsx)(e.td,{children:(0,t.jsx)(e.strong,{children:"Robotics Integration"})}),(0,t.jsx)(e.td,{children:"Through ROS# or Unity Robotics Package"}),(0,t.jsx)(e.td,{children:"Native ROS integration"})]}),(0,t.jsxs)(e.tr,{children:[(0,t.jsx)(e.td,{children:(0,t.jsx)(e.strong,{children:"Development Environment"})}),(0,t.jsx)(e.td,{children:"Visual IDE with C# scripting"}),(0,t.jsx)(e.td,{children:"Text-based SDF/URDF"})]}),(0,t.jsxs)(e.tr,{children:[(0,t.jsx)(e.td,{children:(0,t.jsx)(e.strong,{children:"Real-time Performance"})}),(0,t.jsx)(e.td,{children:"Excellent for visualization"}),(0,t.jsx)(e.td,{children:"Optimized for physics"})]}),(0,t.jsxs)(e.tr,{children:[(0,t.jsx)(e.td,{children:(0,t.jsx)(e.strong,{children:"Learning Curve"})}),(0,t.jsx)(e.td,{children:"Moderate (C# programming)"}),(0,t.jsx)(e.td,{children:"Moderate (SDF/URDF)"})]})]})]}),"\n",(0,t.jsx)(e.h3,{id:"unity-robotics-package",children:"Unity Robotics Package"}),"\n",(0,t.jsx)(e.p,{children:"Unity provides the Unity Robotics Package (URP) and Unity ML-Agents Toolkit specifically for robotics applications:"}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"ROS#"}),": Bridge between Unity and ROS/ROS 2"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"ML-Agents"}),": Machine learning framework for training agents"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Simulation Framework"}),": Tools for creating simulation environments"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Sensor Simulation"}),": Realistic sensor simulation capabilities"]}),"\n"]}),"\n",(0,t.jsx)(e.h2,{id:"setting-up-unity-for-robotics",children:"Setting Up Unity for Robotics"}),"\n",(0,t.jsx)(e.h3,{id:"installation-requirements",children:"Installation Requirements"}),"\n",(0,t.jsxs)(e.ol,{children:["\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Unity Hub"}),": Download from unity.com"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Unity Editor"}),": Version 2021.3 LTS or later recommended"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Unity Robotics Package"}),": Available through Package Manager"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"ROS/ROS 2 Bridge"}),": ROS# package for communication"]}),"\n"]}),"\n",(0,t.jsx)(e.h3,{id:"creating-a-robotics-project",children:"Creating a Robotics Project"}),"\n",(0,t.jsxs)(e.ol,{children:["\n",(0,t.jsxs)(e.li,{children:["\n",(0,t.jsx)(e.p,{children:"Create a new 3D project in Unity"}),"\n"]}),"\n",(0,t.jsxs)(e.li,{children:["\n",(0,t.jsx)(e.p,{children:"Install required packages through Package Manager:"}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsx)(e.li,{children:"Unity Robotics Package"}),"\n",(0,t.jsx)(e.li,{children:"ML-Agents (if needed for training)"}),"\n",(0,t.jsx)(e.li,{children:"ProBuilder (for quick environment creation)"}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(e.li,{children:["\n",(0,t.jsx)(e.p,{children:"Import the ROS# package for ROS/ROS 2 communication"}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(e.h3,{id:"basic-unity-robotics-scene-setup",children:"Basic Unity Robotics Scene Setup"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-csharp",children:'// RobotController.cs - Basic robot controller for Unity\nusing UnityEngine;\nusing Unity.Robotics.ROSTCPConnector;\nusing RosMessageTypes.Std;\nusing RosMessageTypes.Geometry;\n\npublic class RobotController : MonoBehaviour\n{\n    [SerializeField] private float linearSpeed = 1.0f;\n    [SerializeField] private float angularSpeed = 1.0f;\n\n    private ROSConnection ros;\n    private float linearVelocity = 0f;\n    private float angularVelocity = 0f;\n\n    void Start()\n    {\n        // Connect to ROS\n        ros = ROSConnection.GetOrCreateInstance();\n        ros.RegisterPublisher<TwistMsg>("/cmd_vel");\n\n        // Subscribe to velocity commands\n        ros.Subscribe<TwistMsg>("/cmd_vel", ReceiveVelocityCommand);\n    }\n\n    void Update()\n    {\n        // Apply differential drive kinematics\n        if (linearVelocity != 0 || angularVelocity != 0)\n        {\n            // Convert Twist to differential drive\n            float leftWheel = linearVelocity - angularVelocity * 0.5f; // Assuming 1m wheelbase\n            float rightWheel = linearVelocity + angularVelocity * 0.5f;\n\n            // Apply to robot (assuming differential drive)\n            transform.Translate(Vector3.forward * leftWheel * Time.deltaTime * linearSpeed);\n            transform.Rotate(Vector3.up, (rightWheel - leftWheel) * angularSpeed * Time.deltaTime);\n        }\n    }\n\n    void ReceiveVelocityCommand(TwistMsg cmd)\n    {\n        linearVelocity = (float)cmd.linear.x;\n        angularVelocity = (float)cmd.angular.z;\n    }\n\n    void OnDestroy()\n    {\n        if (ros != null)\n            ros.UnregisterPublisher<TwistMsg>("/cmd_vel");\n    }\n}\n'})}),"\n",(0,t.jsx)(e.h2,{id:"physics-simulation-in-unity",children:"Physics Simulation in Unity"}),"\n",(0,t.jsx)(e.h3,{id:"unity-physics-vs-traditional-robotics-physics",children:"Unity Physics vs Traditional Robotics Physics"}),"\n",(0,t.jsx)(e.p,{children:"Unity uses its own physics engine (PhysX) which differs from traditional robotics simulators:"}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Unity Physics"}),": Optimized for games and visual quality"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"ROS Physics"}),": Optimized for accuracy and consistency"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Hybrid Approach"}),": Use Unity for visualization, Gazebo for physics"]}),"\n"]}),"\n",(0,t.jsx)(e.h3,{id:"setting-up-physics-for-humanoid-robots",children:"Setting Up Physics for Humanoid Robots"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-csharp",children:'// HumanoidPhysicsController.cs\nusing UnityEngine;\n\npublic class HumanoidPhysicsController : MonoBehaviour\n{\n    [Header("Balance Parameters")]\n    [SerializeField] private float balanceThreshold = 0.1f;\n    [SerializeField] private float balanceCorrectionStrength = 10f;\n\n    [Header("Joint Configuration")]\n    [SerializeField] private ConfigurableJoint[] joints;\n    [SerializeField] private Transform centerOfMass;\n\n    [Header("Sensor Simulation")]\n    [SerializeField] private Transform[] feetSensors;\n    [SerializeField] private Transform[] imuTransform;\n\n    private Rigidbody rb;\n    private Vector3 targetCOM;\n    private bool[] feetContact = new bool[2]; // Left, Right\n\n    void Start()\n    {\n        rb = GetComponent<Rigidbody>();\n        if (centerOfMass != null)\n        {\n            rb.centerOfMass = centerOfMass.localPosition;\n        }\n\n        SetupJoints();\n    }\n\n    void FixedUpdate()\n    {\n        UpdateSensors();\n        ApplyBalanceControl();\n        UpdateJointControl();\n    }\n\n    void SetupJoints()\n    {\n        foreach (var joint in joints)\n        {\n            // Configure joint limits and spring properties\n            var jointDrive = joint.angularXDrive;\n            jointDrive.positionSpring = 10000f; // Stiffness\n            jointDrive.positionDamper = 1000f;  // Damping\n            joint.angularXDrive = jointDrive;\n\n            var yzDrive = joint.angularYZDrive;\n            yzDrive.positionSpring = 10000f;\n            yzDrive.positionDamper = 1000f;\n            joint.angularYZDrive = yzDrive;\n        }\n    }\n\n    void UpdateSensors()\n    {\n        // Ground contact sensors\n        for (int i = 0; i < feetSensors.Length; i++)\n        {\n            RaycastHit hit;\n            feetContact[i] = Physics.Raycast(feetSensors[i].position,\n                Vector3.down, out hit, 0.1f);\n        }\n\n        // IMU simulation\n        Vector3 angularVelocity = rb.angularVelocity;\n        Vector3 linearAcceleration = rb.velocity / Time.fixedDeltaTime;\n    }\n\n    void ApplyBalanceControl()\n    {\n        // Simple balance control based on COM position\n        Vector3 comOffset = rb.worldCenterOfMass - transform.position;\n        comOffset.y = 0; // Ignore height\n\n        if (comOffset.magnitude > balanceThreshold)\n        {\n            Vector3 correction = -comOffset.normalized * balanceCorrectionStrength * Time.fixedDeltaTime;\n            rb.AddForceAtPosition(correction, rb.worldCenterOfMass, ForceMode.VelocityChange);\n        }\n    }\n\n    void UpdateJointControl()\n    {\n        // Apply joint control based on desired positions\n        // This would typically come from a higher-level controller\n    }\n}\n'})}),"\n",(0,t.jsx)(e.h3,{id:"collision-detection-and-response",children:"Collision Detection and Response"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-csharp",children:'// CollisionHandler.cs\nusing UnityEngine;\n\npublic class CollisionHandler : MonoBehaviour\n{\n    [Header("Collision Response")]\n    [SerializeField] private float collisionThreshold = 10f;\n    [SerializeField] private LayerMask collisionLayers;\n\n    [Header("Damage Control")]\n    [SerializeField] private float maxImpactForce = 100f;\n\n    void OnCollisionEnter(Collision collision)\n    {\n        float impactForce = collision.impulse.magnitude / Time.fixedDeltaTime;\n\n        if (impactForce > collisionThreshold)\n        {\n            Debug.Log($"High impact detected: {impactForce}N");\n\n            if (impactForce > maxImpactForce)\n            {\n                HandleDamage(collision);\n            }\n\n            HandleImpact(collision);\n        }\n    }\n\n    void HandleImpact(Collision collision)\n    {\n        // Play impact sound\n        // Visual effects\n        // Update robot state\n    }\n\n    void HandleDamage(Collision collision)\n    {\n        // Safety shutdown procedures\n        Debug.LogWarning("Potential damage detected - safety shutdown initiated");\n    }\n}\n'})}),"\n",(0,t.jsx)(e.h2,{id:"sensor-simulation-in-unity",children:"Sensor Simulation in Unity"}),"\n",(0,t.jsx)(e.h3,{id:"camera-simulation",children:"Camera Simulation"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-csharp",children:'// CameraSensor.cs\nusing UnityEngine;\nusing Unity.Robotics.ROSTCPConnector;\nusing RosMessageTypes.Sensor;\nusing System.Collections;\n\npublic class CameraSensor : MonoBehaviour\n{\n    [Header("Camera Configuration")]\n    [SerializeField] private Camera cameraComponent;\n    [SerializeField] private int imageWidth = 640;\n    [SerializeField] private int imageHeight = 480;\n    [SerializeField] private float updateRate = 30f; // Hz\n\n    [Header("ROS Communication")]\n    [SerializeField] private string imageTopic = "/camera/image_raw";\n\n    private RenderTexture renderTexture;\n    private Texture2D outputTexture;\n    private ROSConnection ros;\n    private float updateInterval;\n    private float lastUpdateTime;\n\n    void Start()\n    {\n        ros = ROSConnection.GetOrCreateInstance();\n        updateInterval = 1f / updateRate;\n\n        SetupCamera();\n        StartCoroutine(SendImages());\n    }\n\n    void SetupCamera()\n    {\n        // Create render texture for camera\n        renderTexture = new RenderTexture(imageWidth, imageHeight, 24);\n        cameraComponent.targetTexture = renderTexture;\n\n        outputTexture = new Texture2D(imageWidth, imageHeight, TextureFormat.RGB24, false);\n    }\n\n    IEnumerator SendImages()\n    {\n        while (true)\n        {\n            if (Time.time - lastUpdateTime >= updateInterval)\n            {\n                CaptureAndSendImage();\n                lastUpdateTime = Time.time;\n            }\n            yield return null;\n        }\n    }\n\n    void CaptureAndSendImage()\n    {\n        // Set active render texture\n        RenderTexture.active = renderTexture;\n\n        // Read pixels from render texture\n        outputTexture.ReadPixels(new Rect(0, 0, imageWidth, imageHeight), 0, 0);\n        outputTexture.Apply();\n\n        // Convert to ROS image message\n        var imageMsg = CreateImageMessage(outputTexture);\n\n        // Send to ROS\n        ros.Publish(imageTopic, imageMsg);\n\n        // Reset active render texture\n        RenderTexture.active = null;\n    }\n\n    ImageMsg CreateImageMessage(Texture2D texture)\n    {\n        // Convert texture to byte array\n        byte[] imageData = texture.EncodeToJPG();\n\n        var imageMsg = new ImageMsg\n        {\n            header = new std_msgs.HeaderMsg\n            {\n                stamp = new builtin_interfaces.TimeMsg\n                {\n                    sec = (int)Time.time,\n                    nanosec = (uint)((Time.time % 1) * 1e9)\n                },\n                frame_id = transform.name\n            },\n            height = (uint)texture.height,\n            width = (uint)texture.width,\n            encoding = "rgb8",\n            is_bigendian = 0,\n            step = (uint)(texture.width * 3), // 3 bytes per pixel (RGB)\n            data = imageData\n        };\n\n        return imageMsg;\n    }\n}\n'})}),"\n",(0,t.jsx)(e.h3,{id:"lidar-simulation",children:"LIDAR Simulation"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-csharp",children:'// LidarSensor.cs\nusing UnityEngine;\nusing Unity.Robotics.ROSTCPConnector;\nusing RosMessageTypes.Sensor;\nusing System.Collections.Generic;\n\npublic class LidarSensor : MonoBehaviour\n{\n    [Header("LIDAR Configuration")]\n    [SerializeField] private int numberOfRays = 720;\n    [SerializeField] private float fieldOfView = 360f; // degrees\n    [SerializeField] private float maxRange = 30f;\n    [SerializeField] private float minRange = 0.1f;\n    [SerializeField] private float updateRate = 10f; // Hz\n\n    [Header("Noise Parameters")]\n    [SerializeField] private float noiseStdDev = 0.01f;\n\n    [Header("ROS Communication")]\n    [SerializeField] private string scanTopic = "/scan";\n\n    private ROSConnection ros;\n    private float updateInterval;\n    private float lastUpdateTime;\n\n    void Start()\n    {\n        ros = ROSConnection.GetOrCreateInstance();\n        updateInterval = 1f / updateRate;\n    }\n\n    void Update()\n    {\n        if (Time.time - lastUpdateTime >= updateInterval)\n        {\n            PublishLaserScan();\n            lastUpdateTime = Time.time;\n        }\n    }\n\n    void PublishLaserScan()\n    {\n        var scanMsg = new LaserScanMsg\n        {\n            header = new std_msgs.HeaderMsg\n            {\n                stamp = new builtin_interfaces.TimeMsg\n                {\n                    sec = (int)Time.time,\n                    nanosec = (uint)((Time.time % 1) * 1e9)\n                },\n                frame_id = transform.name\n            },\n            angle_min = -fieldOfView * Mathf.Deg2Rad / 2,\n            angle_max = fieldOfView * Mathf.Deg2Rad / 2,\n            angle_increment = (fieldOfView * Mathf.Deg2Rad) / numberOfRays,\n            time_increment = 0,\n            scan_time = 1f / updateRate,\n            range_min = minRange,\n            range_max = maxRange\n        };\n\n        // Sample ranges\n        List<float> ranges = new List<float>();\n        float angleStep = fieldOfView / numberOfRays;\n\n        for (int i = 0; i < numberOfRays; i++)\n        {\n            float angle = (i * angleStep - fieldOfView / 2) * Mathf.Deg2Rad;\n\n            // Calculate ray direction\n            Vector3 rayDirection = new Vector3(\n                Mathf.Cos(angle),\n                0,\n                Mathf.Sin(angle)\n            );\n\n            rayDirection = transform.TransformDirection(rayDirection);\n\n            // Perform raycast\n            RaycastHit hit;\n            if (Physics.Raycast(transform.position, rayDirection, out hit, maxRange))\n            {\n                float range = hit.distance;\n                // Add noise\n                range += Random.Range(-noiseStdDev, noiseStdDev);\n                ranges.Add(Mathf.Clamp(range, minRange, maxRange));\n            }\n            else\n            {\n                ranges.Add(float.PositiveInfinity);\n            }\n        }\n\n        scanMsg.ranges = ranges.ToArray();\n\n        // Intensities (optional)\n        float[] intensities = new float[ranges.Count];\n        for (int i = 0; i < intensities.Length; i++)\n        {\n            intensities[i] = 100f; // Default intensity\n        }\n        scanMsg.intensities = intensities;\n\n        ros.Publish(scanTopic, scanMsg);\n    }\n}\n'})}),"\n",(0,t.jsx)(e.h3,{id:"imu-simulation",children:"IMU Simulation"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-csharp",children:'// IMUSensor.cs\nusing UnityEngine;\nusing Unity.Robotics.ROSTCPConnector;\nusing RosMessageTypes.Sensor;\n\npublic class IMUSensor : MonoBehaviour\n{\n    [Header("Noise Parameters")]\n    [SerializeField] private float angularVelocityNoise = 0.01f;\n    [SerializeField] private float linearAccelerationNoise = 0.1f;\n\n    [Header("ROS Communication")]\n    [SerializeField] private string imuTopic = "/imu/data";\n\n    [Header("Reference Frame")]\n    [SerializeField] private Transform referenceFrame;\n\n    private ROSConnection ros;\n    private Rigidbody rb;\n    private float updateInterval = 0.01f; // 100Hz\n    private float lastUpdateTime;\n\n    void Start()\n    {\n        ros = ROSConnection.GetOrCreateInstance();\n        rb = GetComponent<Rigidbody>();\n    }\n\n    void Update()\n    {\n        if (Time.time - lastUpdateTime >= updateInterval)\n        {\n            PublishIMUData();\n            lastUpdateTime = Time.time;\n        }\n    }\n\n    void PublishIMUData()\n    {\n        var imuMsg = new ImuMsg\n        {\n            header = new std_msgs.HeaderMsg\n            {\n                stamp = new builtin_interfaces.TimeMsg\n                {\n                    sec = (int)Time.time,\n                    nanosec = (uint)((Time.time % 1) * 1e9)\n                },\n                frame_id = transform.name\n            }\n        };\n\n        // Orientation (from Unity rotation)\n        Quaternion rotation = transform.rotation;\n        imuMsg.orientation.x = rotation.x;\n        imuMsg.orientation.y = rotation.y;\n        imuMsg.orientation.z = rotation.z;\n        imuMsg.orientation.w = rotation.w;\n\n        // Angular velocity\n        Vector3 angularVel = rb.angularVelocity;\n        angularVel.x += Random.Range(-angularVelocityNoise, angularVelocityNoise);\n        angularVel.y += Random.Range(-angularVelocityNoise, angularVelocityNoise);\n        angularVel.z += Random.Range(-angularVelocityNoise, angularVelocityNoise);\n\n        imuMsg.angular_velocity.x = angularVel.x;\n        imuMsg.angular_velocity.y = angularVel.y;\n        imuMsg.angular_velocity.z = angularVel.z;\n\n        // Linear acceleration (in world frame, then convert to body frame)\n        Vector3 linearAcc = rb.velocity / Time.deltaTime;\n        linearAcc = transform.InverseTransformDirection(linearAcc - Physics.gravity);\n\n        linearAcc.x += Random.Range(-linearAccelerationNoise, linearAccelerationNoise);\n        linearAcc.y += Random.Range(-linearAccelerationNoise, linearAccelerationNoise);\n        linearAcc.z += Random.Range(-linearAccelerationNoise, linearAccelerationNoise);\n\n        imuMsg.linear_acceleration.x = linearAcc.x;\n        imuMsg.linear_acceleration.y = linearAcc.y;\n        imuMsg.linear_acceleration.z = linearAcc.z;\n\n        // Covariance matrices (set to 0 for now, but should be properly configured)\n        imuMsg.orientation_covariance = new double[9] { -1, 0, 0, 0, 0, 0, 0, 0, 0 };\n        imuMsg.angular_velocity_covariance = new double[9] { 0, 0, 0, 0, 0, 0, 0, 0, 0 };\n        imuMsg.linear_acceleration_covariance = new double[9] { 0, 0, 0, 0, 0, 0, 0, 0, 0 };\n\n        ros.Publish(imuTopic, imuMsg);\n    }\n}\n'})}),"\n",(0,t.jsx)(e.h2,{id:"advanced-visualization-techniques",children:"Advanced Visualization Techniques"}),"\n",(0,t.jsx)(e.h3,{id:"high-fidelity-rendering",children:"High-Fidelity Rendering"}),"\n",(0,t.jsx)(e.p,{children:"Unity excels at creating photorealistic environments and robot models:"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-csharp",children:'// HighFidelityRobot.cs\nusing UnityEngine;\nusing UnityEngine.Rendering;\n\n[RequireComponent(typeof(Renderer))]\npublic class HighFidelityRobot : MonoBehaviour\n{\n    [Header("Material Properties")]\n    [SerializeField] private Material robotMaterial;\n    [SerializeField] private PhysicallyBasedMaterial robotPBR;\n\n    [Header("Lighting Configuration")]\n    [SerializeField] private Light[] robotLights;\n    [SerializeField] private bool useRealisticShading = true;\n\n    [Header("Reflection Probes")]\n    [SerializeField] private ReflectionProbe[] reflectionProbes;\n\n    void Start()\n    {\n        SetupMaterials();\n        ConfigureLighting();\n    }\n\n    void SetupMaterials()\n    {\n        if (robotMaterial != null)\n        {\n            // Configure PBR properties\n            robotMaterial.SetFloat("_Metallic", 0.7f);\n            robotMaterial.SetFloat("_Smoothness", 0.8f);\n            robotMaterial.SetColor("_Color", Color.gray);\n\n            // Add wear and tear effects\n            robotMaterial.SetFloat("_ScratchIntensity", 0.2f);\n        }\n    }\n\n    void ConfigureLighting()\n    {\n        // Set up robot-specific lighting\n        foreach (var light in robotLights)\n        {\n            light.shadows = LightShadows.Soft;\n            light.intensity = 1.5f;\n        }\n    }\n\n    public void UpdateRobotState(bool poweredOn, bool inMotion)\n    {\n        // Update material properties based on robot state\n        if (robotMaterial != null)\n        {\n            float emission = poweredOn ? 0.2f : 0f;\n            robotMaterial.SetColor("_EmissionColor",\n                new Color(emission, emission, emission));\n\n            // Add motion blur effect when moving\n            if (inMotion)\n            {\n                // Apply motion blur shader or post-processing effect\n            }\n        }\n    }\n}\n'})}),"\n",(0,t.jsx)(e.h3,{id:"environment-creation",children:"Environment Creation"}),"\n",(0,t.jsx)(e.p,{children:"Creating realistic environments for humanoid robot testing:"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-csharp",children:'// EnvironmentManager.cs\nusing UnityEngine;\nusing System.Collections.Generic;\n\npublic class EnvironmentManager : MonoBehaviour\n{\n    [Header("Environment Prefabs")]\n    [SerializeField] private GameObject[] indoorPrefabs;\n    [SerializeField] private GameObject[] outdoorPrefabs;\n    [SerializeField] private GameObject[] obstaclePrefabs;\n\n    [Header("Terrain Configuration")]\n    [SerializeField] private Terrain terrain;\n    [SerializeField] private float terrainScale = 100f;\n\n    [Header("Weather System")]\n    [SerializeField] private bool enableWeather = true;\n    [SerializeField] private float weatherChangeInterval = 300f; // 5 minutes\n\n    private List<GameObject> spawnedObjects = new List<GameObject>();\n    private float lastWeatherChange;\n\n    void Start()\n    {\n        GenerateEnvironment();\n        StartCoroutine(WeatherSystem());\n    }\n\n    void GenerateEnvironment()\n    {\n        // Create indoor environment\n        if (indoorPrefabs.Length > 0)\n        {\n            CreateIndoorEnvironment();\n        }\n\n        // Add obstacles and interactive elements\n        SpawnObstacles();\n\n        // Configure terrain\n        if (terrain != null)\n        {\n            ConfigureTerrain();\n        }\n    }\n\n    void CreateIndoorEnvironment()\n    {\n        // Create rooms, corridors, furniture\n        foreach (var prefab in indoorPrefabs)\n        {\n            Vector3 position = new Vector3(\n                Random.Range(-terrainScale/2, terrainScale/2),\n                0,\n                Random.Range(-terrainScale/2, terrainScale/2)\n            );\n\n            GameObject instance = Instantiate(prefab, position, Quaternion.identity);\n            spawnedObjects.Add(instance);\n        }\n    }\n\n    void SpawnObstacles()\n    {\n        for (int i = 0; i < 20; i++) // Spawn 20 random obstacles\n        {\n            int prefabIndex = Random.Range(0, obstaclePrefabs.Length);\n            Vector3 position = new Vector3(\n                Random.Range(-terrainScale/3, terrainScale/3),\n                0.5f, // Half the height of a human\n                Random.Range(-terrainScale/3, terrainScale/3)\n            );\n\n            GameObject obstacle = Instantiate(obstaclePrefabs[prefabIndex], position, Quaternion.identity);\n            spawnedObjects.Add(obstacle);\n        }\n    }\n\n    void ConfigureTerrain()\n    {\n        // Configure terrain properties for realistic ground\n        terrain.terrainData.size = new Vector3(terrainScale, 20f, terrainScale);\n\n        // Add texture layers for different ground types\n        SplatPrototype[] splatPrototypes = new SplatPrototype[3];\n\n        // Grass\n        splatPrototypes[0] = new SplatPrototype();\n        splatPrototypes[0].texture = Resources.Load<Texture2D>("TerrainTextures/grass");\n        splatPrototypes[0].tileSize = new Vector2(5f, 5f);\n\n        // Concrete\n        splatPrototypes[1] = new SplatPrototype();\n        splatPrototypes[1].texture = Resources.Load<Texture2D>("TerrainTextures/concrete");\n        splatPrototypes[1].tileSize = new Vector2(2f, 2f);\n\n        // Dirt\n        splatPrototypes[2] = new SplatPrototype();\n        splatPrototypes[2].texture = Resources.Load<Texture2D>("TerrainTextures/dirt");\n        splatPrototypes[2].tileSize = new Vector2(3f, 3f);\n\n        terrain.terrainData.splatPrototypes = splatPrototypes;\n\n        // Generate alphamap for texture blending\n        float[,,] alphamap = new float[terrain.terrainData.alphamapWidth,\n                                       terrain.terrainData.alphamapHeight,\n                                       splatPrototypes.Length];\n\n        // Simple pattern - grass in center, concrete around edges\n        for (int y = 0; y < terrain.terrainData.alphamapHeight; y++)\n        {\n            for (int x = 0; x < terrain.terrainData.alphamapWidth; x++)\n            {\n                float normalizedX = (float)x / terrain.terrainData.alphamapWidth;\n                float normalizedY = (float)y / terrain.terrainData.alphamapHeight;\n\n                float distanceFromCenter = Mathf.Sqrt(\n                    Mathf.Pow(normalizedX - 0.5f, 2) +\n                    Mathf.Pow(normalizedY - 0.5f, 2)\n                );\n\n                if (distanceFromCenter < 0.3f)\n                {\n                    alphamap[x, y, 0] = 1f; // Grass\n                    alphamap[x, y, 1] = 0f;\n                    alphamap[x, y, 2] = 0f;\n                }\n                else if (distanceFromCenter < 0.4f)\n                {\n                    alphamap[x, y, 0] = 0.5f; // Mixed\n                    alphamap[x, y, 1] = 0.5f;\n                    alphamap[x, y, 2] = 0f;\n                }\n                else\n                {\n                    alphamap[x, y, 0] = 0f;\n                    alphamap[x, y, 1] = 1f; // Concrete\n                    alphamap[x, y, 2] = 0f;\n                }\n            }\n        }\n\n        terrain.terrainData.SetAlphamaps(0, 0, alphamap);\n    }\n\n    System.Collections.IEnumerator WeatherSystem()\n    {\n        while (true)\n        {\n            if (enableWeather)\n            {\n                ChangeWeather();\n            }\n            yield return new WaitForSeconds(weatherChangeInterval);\n        }\n    }\n\n    void ChangeWeather()\n    {\n        // Simple weather system - could be expanded with particle systems\n        float weatherType = Random.value;\n\n        if (weatherType < 0.3f)\n        {\n            // Sunny\n            RenderSettings.ambientLight = new Color(0.8f, 0.8f, 0.8f);\n            RenderSettings.fog = false;\n        }\n        else if (weatherType < 0.6f)\n        {\n            // Cloudy\n            RenderSettings.ambientLight = new Color(0.6f, 0.6f, 0.7f);\n            RenderSettings.fog = true;\n            RenderSettings.fogColor = new Color(0.7f, 0.7f, 0.8f);\n            RenderSettings.fogDensity = 0.01f;\n        }\n        else\n        {\n            // Overcast/Rainy\n            RenderSettings.ambientLight = new Color(0.4f, 0.4f, 0.5f);\n            RenderSettings.fog = true;\n            RenderSettings.fogColor = new Color(0.5f, 0.5f, 0.6f);\n            RenderSettings.fogDensity = 0.02f;\n        }\n    }\n}\n'})}),"\n",(0,t.jsx)(e.h2,{id:"integration-with-ros-2",children:"Integration with ROS 2"}),"\n",(0,t.jsx)(e.h3,{id:"ros-bridge-setup",children:"ROS# Bridge Setup"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-csharp",children:'// ROSBridgeManager.cs\nusing UnityEngine;\nusing Unity.Robotics.ROSTCPConnector;\nusing RosMessageTypes.Std;\n\npublic class ROSBridgeManager : MonoBehaviour\n{\n    [Header("ROS Connection")]\n    [SerializeField] private string rosIPAddress = "127.0.0.1";\n    [SerializeField] private int rosPort = 10000;\n\n    [Header("Robot Configuration")]\n    [SerializeField] private string robotNamespace = "/humanoid_robot";\n\n    private ROSConnection ros;\n    private bool isConnected = false;\n\n    void Start()\n    {\n        ConnectToROS();\n        SetupROSCommunications();\n    }\n\n    void ConnectToROS()\n    {\n        ros = ROSConnection.GetOrCreateInstance();\n        ros.Initialize(rosIPAddress, rosPort);\n\n        // Test connection\n        InvokeRepeating("TestConnection", 1f, 5f);\n    }\n\n    void SetupROSCommunications()\n    {\n        // Publisher setup\n        ros.RegisterPublisher<UInt8Msg>($"{robotNamespace}/status");\n        ros.RegisterPublisher<StringMsg>($"{robotNamespace}/log");\n\n        // Subscriber setup\n        ros.Subscribe<StringMsg>($"{robotNamespace}/command", HandleCommand);\n    }\n\n    void TestConnection()\n    {\n        var testMsg = new UInt8Msg();\n        testMsg.data = 1;\n        ros.Publish($"{robotNamespace}/heartbeat", testMsg);\n    }\n\n    void HandleCommand(StringMsg cmd)\n    {\n        Debug.Log($"Received command: {cmd.data}");\n\n        // Process command and update robot state\n        ProcessRobotCommand(cmd.data);\n    }\n\n    void ProcessRobotCommand(string command)\n    {\n        switch (command.ToLower())\n        {\n            case "move_forward":\n                // Trigger movement\n                break;\n            case "turn_left":\n                // Trigger turn\n                break;\n            case "home_position":\n                // Return to home position\n                break;\n            default:\n                Debug.LogWarning($"Unknown command: {command}");\n                break;\n        }\n    }\n\n    void OnDestroy()\n    {\n        if (ros != null)\n        {\n            ros.Disconnect();\n        }\n    }\n}\n'})}),"\n",(0,t.jsx)(e.h3,{id:"tf-transform-broadcasting",children:"TF (Transform) Broadcasting"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-csharp",children:'// TFBroadcaster.cs\nusing UnityEngine;\nusing Unity.Robotics.ROSTCPConnector;\nusing RosMessageTypes.Geometry;\nusing RosMessageTypes.Std;\n\npublic class TFBroadcaster : MonoBehaviour\n{\n    [Header("TF Configuration")]\n    [SerializeField] private Transform[] robotLinks;\n    [SerializeField] private string[] linkNames;\n    [SerializeField] private string baseFrame = "odom";\n\n    private ROSConnection ros;\n    private float tfUpdateInterval = 0.05f; // 20Hz\n    private float lastTFUpdate;\n\n    void Start()\n    {\n        ros = ROSConnection.GetOrCreateInstance();\n\n        if (robotLinks.Length != linkNames.Length)\n        {\n            Debug.LogError("Robot links and link names arrays must have the same length!");\n        }\n    }\n\n    void Update()\n    {\n        if (Time.time - lastTFUpdate >= tfUpdateInterval)\n        {\n            BroadcastTransforms();\n            lastTFUpdate = Time.time;\n        }\n    }\n\n    void BroadcastTransforms()\n    {\n        var tfArray = new RosMessageTypes.Geometry.TFMessageMsg();\n        tfArray.transforms = new TransformStampedMsg[robotLinks.Length];\n\n        for (int i = 0; i < robotLinks.Length; i++)\n        {\n            tfArray.transforms[i] = CreateTransformStamped(\n                baseFrame,\n                linkNames[i],\n                robotLinks[i]\n            );\n        }\n\n        ros.Publish("tf", tfArray);\n    }\n\n    TransformStampedMsg CreateTransformStamped(string parentFrame, string childFrame, Transform transform)\n    {\n        var tf = new TransformStampedMsg\n        {\n            header = new HeaderMsg\n            {\n                stamp = new builtin_interfaces.TimeMsg\n                {\n                    sec = (int)Time.time,\n                    nanosec = (uint)((Time.time % 1) * 1e9)\n                },\n                frame_id = parentFrame\n            },\n            child_frame_id = childFrame,\n            transform = new TransformMsg\n            {\n                translation = new Vector3Msg\n                {\n                    x = transform.position.x,\n                    y = transform.position.y,\n                    z = transform.position.z\n                },\n                rotation = new QuaternionMsg\n                {\n                    x = transform.rotation.x,\n                    y = transform.rotation.y,\n                    z = transform.rotation.z,\n                    w = transform.rotation.w\n                }\n            }\n        };\n\n        return tf;\n    }\n}\n'})}),"\n",(0,t.jsx)(e.h2,{id:"performance-optimization",children:"Performance Optimization"}),"\n",(0,t.jsx)(e.h3,{id:"unity-performance-considerations",children:"Unity Performance Considerations"}),"\n",(0,t.jsx)(e.p,{children:"When creating high-fidelity visualizations for robotics:"}),"\n",(0,t.jsxs)(e.ol,{children:["\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"LOD (Level of Detail)"}),": Use different models based on distance"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Occlusion Culling"}),": Hide objects not visible to cameras"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Texture Compression"}),": Use appropriate texture formats"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Shader Optimization"}),": Use mobile/desktop optimized shaders"]}),"\n"]}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-csharp",children:"// LODManager.cs\nusing UnityEngine;\n\npublic class LODManager : MonoBehaviour\n{\n    [System.Serializable]\n    public class LODLevel\n    {\n        public string name;\n        public GameObject model;\n        public float distance;\n        public Material[] materials;\n    }\n\n    [SerializeField] private LODLevel[] lodLevels;\n    [SerializeField] private Transform playerCamera;\n    [SerializeField] private float lodUpdateInterval = 0.1f;\n\n    private float lastLODUpdate;\n    private int currentLODLevel = 0;\n\n    void Update()\n    {\n        if (Time.time - lastLODUpdate >= lodUpdateInterval)\n        {\n            UpdateLOD();\n            lastLODUpdate = Time.time;\n        }\n    }\n\n    void UpdateLOD()\n    {\n        if (playerCamera == null) return;\n\n        float distance = Vector3.Distance(transform.position, playerCamera.position);\n\n        // Find appropriate LOD level\n        int newLODLevel = 0;\n        for (int i = 0; i < lodLevels.Length; i++)\n        {\n            if (distance <= lodLevels[i].distance)\n            {\n                newLODLevel = i;\n                break;\n            }\n        }\n\n        // Switch to new LOD level if needed\n        if (newLODLevel != currentLODLevel)\n        {\n            SwitchLOD(newLODLevel);\n            currentLODLevel = newLODLevel;\n        }\n    }\n\n    void SwitchLOD(int levelIndex)\n    {\n        // Hide all LOD models\n        foreach (var lod in lodLevels)\n        {\n            if (lod.model != null)\n                lod.model.SetActive(false);\n        }\n\n        // Show selected LOD model\n        if (levelIndex < lodLevels.Length && lodLevels[levelIndex].model != null)\n        {\n            lodLevels[levelIndex].model.SetActive(true);\n\n            // Apply appropriate materials\n            ApplyMaterials(levelIndex);\n        }\n    }\n\n    void ApplyMaterials(int levelIndex)\n    {\n        var materials = lodLevels[levelIndex].materials;\n        var renderers = lodLevels[levelIndex].model.GetComponentsInChildren<Renderer>();\n\n        for (int i = 0; i < renderers.Length && i < materials.Length; i++)\n        {\n            renderers[i].material = materials[i];\n        }\n    }\n}\n"})}),"\n",(0,t.jsx)(e.h2,{id:"best-practices-for-unity-robotics",children:"Best Practices for Unity Robotics"}),"\n",(0,t.jsx)(e.h3,{id:"architecture-best-practices",children:"Architecture Best Practices"}),"\n",(0,t.jsxs)(e.ol,{children:["\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Modular Design"}),": Separate visualization from physics simulation"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Performance Monitoring"}),": Monitor frame rates and optimize accordingly"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Realistic Sensor Models"}),": Include noise and limitations"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"ROS Integration"}),": Properly handle ROS message types and timing"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Scalability"}),": Design systems that can handle multiple robots"]}),"\n"]}),"\n",(0,t.jsx)(e.h3,{id:"visualization-best-practices",children:"Visualization Best Practices"}),"\n",(0,t.jsxs)(e.ol,{children:["\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Realistic Lighting"}),": Use physically-based rendering"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Environmental Context"}),": Create meaningful environments"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Sensor Visualization"}),": Show sensor data overlay when needed"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Debug Visualization"}),": Include tools for debugging robot state"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"User Interface"}),": Provide clear feedback about robot status"]}),"\n"]}),"\n",(0,t.jsx)(e.h2,{id:"troubleshooting-common-issues",children:"Troubleshooting Common Issues"}),"\n",(0,t.jsx)(e.h3,{id:"performance-issues",children:"Performance Issues"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-csharp",children:'// PerformanceMonitor.cs\nusing UnityEngine;\nusing UnityEngine.UI;\n\npublic class PerformanceMonitor : MonoBehaviour\n{\n    [SerializeField] private Text performanceText;\n    [SerializeField] private float updateInterval = 0.5f;\n\n    private float lastUpdate;\n    private int frameCount = 0;\n    private float accumulatedFrameTime = 0f;\n\n    void Update()\n    {\n        if (Time.time - lastUpdate >= updateInterval)\n        {\n            float avgFrameTime = accumulatedFrameTime / frameCount;\n            int avgFPS = Mathf.RoundToInt(1f / avgFrameTime);\n\n            performanceText.text = $"FPS: {avgFPS}\\nFrame Time: {avgFrameTime * 1000f:F1}ms";\n\n            frameCount = 0;\n            accumulatedFrameTime = 0f;\n            lastUpdate = Time.time;\n        }\n\n        frameCount++;\n        accumulatedFrameTime += Time.unscaledDeltaTime;\n    }\n}\n'})}),"\n",(0,t.jsx)(e.h3,{id:"sensor-synchronization",children:"Sensor Synchronization"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-csharp",children:"// SensorSynchronizer.cs\nusing UnityEngine;\nusing System.Collections.Generic;\n\npublic class SensorSynchronizer : MonoBehaviour\n{\n    [SerializeField] private MonoBehaviour[] sensors;\n    [SerializeField] private float syncInterval = 0.01f; // 100Hz\n\n    private float lastSyncTime;\n    private Queue<float> syncQueue = new Queue<float>();\n\n    void Update()\n    {\n        if (Time.time - lastSyncTime >= syncInterval)\n        {\n            SynchronizeSensors();\n            lastSyncTime = Time.time;\n        }\n    }\n\n    void SynchronizeSensors()\n    {\n        foreach (var sensor in sensors)\n        {\n            if (sensor != null)\n            {\n                // Trigger sensor update\n                // This ensures all sensors update at the same time\n            }\n        }\n    }\n}\n"})}),"\n",(0,t.jsx)(e.h2,{id:"knowledge-check",children:"Knowledge Check"}),"\n",(0,t.jsxs)(e.ol,{children:["\n",(0,t.jsx)(e.li,{children:"What are the key advantages of using Unity over Gazebo for robotics visualization?"}),"\n",(0,t.jsx)(e.li,{children:"How do you implement realistic sensor simulation in Unity?"}),"\n",(0,t.jsx)(e.li,{children:"What are the essential components for ROS integration in Unity?"}),"\n",(0,t.jsx)(e.li,{children:"How do you optimize Unity performance for high-fidelity robot visualization?"}),"\n"]}),"\n",(0,t.jsx)(e.h2,{id:"summary",children:"Summary"}),"\n",(0,t.jsx)(e.p,{children:"This chapter explored Unity's role in robotics visualization and simulation, covering physics simulation, sensor modeling, and high-fidelity rendering techniques. We learned how to set up Unity for robotics applications, implement realistic sensor simulation, and integrate with ROS 2 for complete robot simulation systems. The chapter also provided best practices for performance optimization and system architecture."}),"\n",(0,t.jsx)(e.h2,{id:"next-steps",children:"Next Steps"}),"\n",(0,t.jsx)(e.p,{children:"In the next module, we'll explore the AI-Robot Brain with NVIDIA Isaac SDK and Isaac Sim, learning about photorealistic simulation, synthetic data generation, and advanced perception techniques for humanoid robotics."})]})}function m(n={}){const{wrapper:e}={...(0,a.R)(),...n.components};return e?(0,t.jsx)(e,{...n,children:(0,t.jsx)(d,{...n})}):d(n)}}}]);